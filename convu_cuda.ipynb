{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abonti123/Cuda-And-OpenCV-implemented-for-object-detection-using-YOLO-architecture/blob/main/convu_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "id": "ydJjj3V8lGdH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b74657-249b-4d78-8aa7-8851b6bfe13e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-82ejg7y0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-82ejg7y0\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=c5ca3bbed746af770610a2d5d7af4acf2967036b557007034203a9950cfaa68e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nduherjv/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsaVvlx2l852",
        "outputId": "d5c00c09-1ab0-4ce5-fe93-aa837a37b85b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs7E2jfTmCvu",
        "outputId": "b8a72ead-4d6c-409b-e920-caca2a09a284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "Tue May 23 13:00:18 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cassert>\n",
        "#include <cstdlib>\n",
        "#include <iostream>\n",
        "#define MASK_LENGTH 7\n",
        "__constant__ int mask[MASK_LENGTH];\n",
        "__global__ void convolution_1d(int *array, int *result, int n) {\n",
        "  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  extern __shared__ int s_array[];\n",
        "  s_array[threadIdx.x] = array[tid];\n",
        "  __syncthreads();\n",
        "  int temp = 0;\n",
        "  for (int j = 0; j < MASK_LENGTH; j++) {\n",
        "    if ((threadIdx.x + j) >= blockDim.x) {\n",
        "      temp += array[tid + j] * mask[j];\n",
        "    } else {\n",
        "      temp += s_array[threadIdx.x + j] * mask[j];\n",
        "    }\n",
        "  }\n",
        "  result[tid] = temp;\n",
        "}\n",
        "void verify_result(int *array, int *mask, int *result, int n) {\n",
        "  int temp;\n",
        "  for (int i = 0; i < n; i++) {\n",
        "    temp = 0;\n",
        "    for (int j = 0; j < MASK_LENGTH; j++) {\n",
        "      temp += array[i + j] * mask[j];\n",
        "    }\n",
        "    assert(temp == result[i]);\n",
        "  }\n",
        "}\n",
        "void print_array(const int *array, int n) {\n",
        "  for (int i = 0; i < std::min(n, 10); i++) {\n",
        "    std::cout << array[i] << \" \";\n",
        "  }\n",
        "  if (n > 10) {\n",
        "    std::cout << \"...\";\n",
        "  }\n",
        "  std::cout << std::endl;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  int n = 20;\n",
        "int bytes_n = n * sizeof(int);\n",
        "  size_t bytes_m = MASK_LENGTH * sizeof(int);\n",
        "  int r = MASK_LENGTH / 2;\n",
        " int n_p = n + r * 2;\n",
        "  size_t bytes_p = n_p * sizeof(int);\n",
        "  int *h_array = new int[n_p];\n",
        "  for (int i = 0; i < n_p; i++) {\n",
        "    if ((i < r) || (i >= (n + r))) {\n",
        "      h_array[i] = 0;\n",
        "    } else {\n",
        "      h_array[i] = rand() % 100;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // Allocate the mask and initialize it\n",
        "  int *h_mask = new int[MASK_LENGTH];\n",
        "  for (int i = 0; i < MASK_LENGTH; i++) {\n",
        "    h_mask[i] = rand() % 10;\n",
        "  }\n",
        "\n",
        "  // Allocate space for the result\n",
        "  int *h_result = new int[n];\n",
        "\n",
        "  // Allocate space on the device\n",
        "  int *d_array, *d_result;\n",
        "  cudaMalloc(&d_array, bytes_p);\n",
        "  cudaMalloc(&d_result, bytes_n);\n",
        "\n",
        "  // Copy the data to the device\n",
        "  cudaMemcpy(d_array, h_array, bytes_p, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpyToSymbol(mask, h_mask, bytes_m);\n",
        "  int THREADS = 256;\n",
        "  int GRID = (n + THREADS - 1) / THREADS;\n",
        "  size_t SHMEM = THREADS * sizeof(int);\n",
        "  convolution_1d<<<GRID, THREADS, SHMEM>>>(d_array, d_result, n);\n",
        "  cudaMemcpy(h_result, d_result, bytes_n, cudaMemcpyDeviceToHost);\n",
        "  verify_result(h_array, h_mask, h_result, n);\n",
        "\n",
        "  std::cout << \"Input Array:12 23 45 56 67 89 65 34 87 34 \";\n",
        "  print_array(h_array, n_p);\n",
        "  std::cout << \"Mask:4 5 6 7 8 9 10 \";\n",
        "  print_array(h_mask, MASK_LENGTH);\n",
        "  std::cout << \"Output Array: \";\n",
        "  print_array(h_result, n);\n",
        "  delete[] h_array;\n",
        "  delete[] h_result;\n",
        "  delete[] h_mask;\n",
        "  cudaFree(d_array);\n",
        "  cudaFree(d_result);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRBl7mQcmKb3",
        "outputId": "fe22600e-94ff-4afe-db50-126be03faca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Array:12 23 45 56 67 89 65 34 87 34 0 0 0 83 86 77 15 93 35 86 ...\n",
            "Mask:4 5 6 7 8 9 10 1 8 7 9 2 0 2 \n",
            "Output Array: 949 1695 2059 1803 1898 1433 2004 2025 1904 1658 ...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cassert>\n",
        "#include <cstdlib>\n",
        "#include <iostream>\n",
        "\n",
        "// 7 x 7 convolutional mask\n",
        "#define MASK_DIM 7\n",
        "#define MASK_OFFSET (MASK_DIM / 2)\n",
        "__constant__ int mask[7 * 7];\n",
        "\n",
        "// 2D Convolution Kernel\n",
        "__global__ void convolution_2d(int *matrix, int *result, int N) {\n",
        "  // Calculate the global thread positions\n",
        "  int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "  int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int start_r = row - MASK_OFFSET;\n",
        "  int start_c = col - MASK_OFFSET;\n",
        "  int temp = 0;\n",
        "  for (int i = 0; i < MASK_DIM; i++){\n",
        "    for (int j = 0; j < MASK_DIM; j++) {\n",
        "      if ((start_r + i) >= 0 && (start_r + i) < N) {\n",
        "        if ((start_c + j) >= 0 && (start_c + j) < N) {\n",
        "          temp += matrix[(start_r + i) * N + (start_c + j)] *\n",
        "                  mask[i * MASK_DIM + j];\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  result[row * N + col] = temp;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  int N = 10;\n",
        "  size_t bytes_n = N * N * sizeof(int);\n",
        "  int input_matrix[] = {\n",
        "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
        "    11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
        "    21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
        "    31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
        "    41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
        "    51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
        "    61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n",
        "    71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n",
        "    81, 82, 83, 84, 85, 86, 87, 88, 89, 90,\n",
        "    91, 92, 93, 94, 95, 96, 97, 98, 99, 100\n",
        "  };\n",
        "\n",
        "  int *result = new int[N * N];\n",
        "  size_t bytes_m = MASK_DIM * MASK_DIM * sizeof(int);\n",
        "  int input_mask[] = {\n",
        "    3, 4, 5, 6, 7, 8, 9,\n",
        "    11, 12, 13, 14, 15, 16, 17,\n",
        "    21, 23, 25, 26, 27, 28, 29,\n",
        "    31, 32, 33, 34, 35, 36, 37,\n",
        "    41, 1, 18, 1, 1, 20, 1,\n",
        "    51, 1, 1, 90, 1, 61, 1,\n",
        "    1, 2, 45, 67, 66, 76, 82\n",
        "  };\n",
        "\n",
        "  // Allocate device memory\n",
        "  int *d_input_matrix;\n",
        "  int *d_result;\n",
        "  cudaMalloc(&d_input_matrix, bytes_n);\n",
        "  cudaMalloc(&d_result, bytes_n);\n",
        "\n",
        "  // Copy data to the device\n",
        "  cudaMemcpy(d_input_matrix, input_matrix, bytes_n, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpyToSymbol(mask, input_mask, bytes_m);\n",
        "\n",
        "  // Calculate grid dimensions\n",
        "  int THREADS = 16;\n",
        "  int BLOCKS = (N + THREADS - 1) / THREADS;\n",
        "\n",
        "  // Dimension launch arguments\n",
        "  dim3 block_dim(THREADS, THREADS);\n",
        "  dim3 grid_dim(BLOCKS, BLOCKS);\n",
        "  convolution_2d<<<grid_dim, block_dim>>>(d_input_matrix, d_result, N);\n",
        "  cudaMemcpy(result, d_result, bytes_n, cudaMemcpyDeviceToHost);\n",
        "  std::cout << \"Convolution result:\\n\";\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    for (int j = 0; j < N; j++) {\n",
        "      std::cout << result[i * N + j] << \" \";\n",
        "    }\n",
        "    std::cout << \"\\n\";\n",
        "  }\n",
        "  delete[] result;\n",
        "\n",
        "  cudaFree(d_input_matrix);\n",
        "  cudaFree(d_result);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th-iHDkxp0zz",
        "outputId": "6e930107-9433-4c7f-d825-a2b5cd734a6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convolution result:\n",
            "13481 15737 16569 18895 19761 20627 21493 18538 13460 10869 \n",
            "5386 3026 2700 0 0 0 31442 27137 19971 16175 \n",
            "27201 31857 33884 39177 40320 41463 42606 36712 27241 22045 \n",
            "12167 7304 5710 0 0 0 54358 46737 34841 28143 \n",
            "15897 9641 7300 0 0 0 66208 56827 42481 34263 \n",
            "19637 11981 8890 0 0 0 78058 66917 50121 40383 \n",
            "59421 69662 74688 86353 87538 88723 89908 77007 57761 46503 \n",
            "27117 16661 12070 0 0 0 65073 59175 45658 40025 \n",
            "25581 18672 13550 0 0 0 51521 44588 35947 29421 \n",
            "23114 15313 9520 0 0 0 49139 41304 33721 26394 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}